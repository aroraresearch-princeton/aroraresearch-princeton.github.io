<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Arora Research Lab | Arora Research Lab @ Princeton</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Arora Research Lab" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Arora Research Lab @ Princeton" />
<meta property="og:description" content="Arora Research Lab @ Princeton" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Arora Research Lab" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Arora Research Lab" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Arora Research Lab @ Princeton","headline":"Arora Research Lab","name":"Arora Research Lab","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">Arora Research Lab</a></h1>

        

        <p>Arora Research Lab @ Princeton</p>

        <p><a href="http://localhost:4000/pages/team.html">Team</a>&emsp;/&emsp;<a
            href="http://localhost:4000/pages/publications.html">Publications</a>&emsp;/&emsp;<a href="http://localhost:4000/pages/blogs.html">Blogs</a></p>
      </header>
      <section>

      <p><img src="/assets/img/group-photo-2024.jpg" style="height: 100%; width:67%; display: block; margin-left: auto; margin-right: auto; padding: 0px 3px 0px px; background-color: #fefefe;" /></p>

<h2 id="research">Research</h2>

<p>Our research lab develops conceptual understanding of AI models, including training techniques, datasets, model interpretability and model evaluations. Recent works involve new ways of training and evaluating models using “skills”, which are themselves elicited from powerful AI models, and in turn can be used to generate very effective pipelines for improving AI models using synthetic training data. Many of our papers involve mathematical analysis as well as experiments.</p>

<hr />

<h2 id="news">News</h2>

<style>
    table,
    tr,
    td {
        border: none;
    }
</style>

<div style="height:250px;overflow:auto;border:0px;border-collapse: collapse;">
    <table border="none" style="border:0px;border-collapse: collapse;" rules="none">
        <colgroup>
            <col span="1" style="width: 12%;" />
            <col span="1" style="width: 88%;" />
        </colgroup>
        <tbody>
            
            
            <tr>
                
                    
                        <td><b>[05/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2503.01821"><i>On the Power of Context-Enhanced Learning in LLMs</i></a> was accepted to ICML 2025 <b>(Spotlight)</b>! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[05/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2501.02669"><i>Generalizing from SIMPLE to HARD Visual Reasoning: Can We Mitigate Modality Imbalance in VLMs?</i></a> was accepted to ICML 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[05/2025]</b></td>
                        
                            <td> Check out our new paper <a href="https://arxiv.org/abs/2507.07981"><i>Why is Your Language Model a Poor Implicit Reward Model?</i></a>!</td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[03/2025]</b></td>
                        <td>Congrats to Abhishek Panigrahi on being named 2025 Apple Scholar in AIML!</td>
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[03/2025]</b></td>
                        
                            <td> Check out our new paper <a href="https://arxiv.org/abs/2503.15477"><i>What Makes a Reward Model a Good Teacher? An Optimization Perspective</i></a>!</td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[02/2025]</b></td>
                        
                            <td> Check out our new paper <a href="https://arxiv.org/abs/2502.07640"><i>Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving</i></a>!</td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[02/2025]</b></td>
                        
                            <td> Check out our new paper <a href="https://arxiv.org/abs/2502.03669"><i>Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set</i></a>!</td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2408.14774"><i>Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning</i></a> was accepted to ICLR 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2410.05464"><i>Progressive distillation induces an implicit curriculum</i></a> was accepted to ICLR 2025 <b>(Oral)</b>! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2410.08847"><i>Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization</i></a> was accepted to ICLR 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2411.12600"><i>Provable unlearning in topic modeling and downstream tasks</i></a> was accepted to ICLR 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2410.11820"><i>Adaptive Data Optimization: Dynamic Sample Selection with Scaling Law</i></a> was accepted to ICLR 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
                    
                        <td><b>[01/2025]</b></td>
                        
                            <td> New paper <a href="https://arxiv.org/abs/2407.06460"><i>MUSE: Machine Unlearning Six-Way Evaluation for Language Models</i></a> was accepted to ICLR 2025! </td>
                        
                    
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
            
            <tr>
                
            </tr>
            
        </tbody>
    </table>
</div>
<p> </p>

<p><a href="/pages/news_archives.html">News archives</a></p>

<hr />

<h2 id="selected-talks">Selected Talks</h2>

<!-- <div class="video-container">
        <div class="video-wrapper">
            <iframe 
                src="https://www.youtube.com/embed/cntj4vN7mG0" 
                title="YouTube video 1"
                frameborder="0" 
                allowfullscreen>
            </iframe>
        </div>
        <div class="video-wrapper">
            <iframe 
                src="https://www.youtube.com/embed/RQ9OwONya2s?si=92vTxSNT-nnrDnH9" 
                title="YouTube video 2"
                frameborder="0" 
                allowfullscreen>
            </iframe>
        </div>
    </div> -->

<div class="talks">
    
        
        
        
        
        <p><a href="https://www.youtube.com/watch?v=cntj4vN7mG0">LLM Metacognition: Understanding and Leveraging LLMs' "Thinking about Thinking"</a> (Simons Institute, 2024)</p>
        <div class="video-container">
            <div class="video-wrapper">
                <iframe src="https://www.youtube.com/embed/cntj4vN7mG0" frameborder="0" allowfullscreen="">
                </iframe>
            </div>
        </div>
        &nbsp;
        
        
        
        
        
        <p><a href="https://www.youtube.com/watch?v=RQ9OwONya2s?si=92vTxSNT-nnrDnH9">Why do large language models display new and complex skills?</a> (University of Michigan Computer Science and Engineering, 2023)</p>
        <div class="video-container">
            <div class="video-wrapper">
                <iframe src="https://www.youtube.com/embed/RQ9OwONya2s?si=92vTxSNT-nnrDnH9" frameborder="0" allowfullscreen="">
                </iframe>
            </div>
        </div>
        &nbsp;
        
        
        
        
        
        <p><a href="https://www.youtube.com/watch?v=0D23NeBjCeQ">A Theory for Emergence of Complex Skills in Language Models</a> (Simons Institute, 2023)</p>
        <div class="video-container">
            <div class="video-wrapper">
                <iframe src="https://www.youtube.com/embed/0D23NeBjCeQ" frameborder="0" allowfullscreen="">
                </iframe>
            </div>
        </div>
        &nbsp;
        
        
    
</div>

<!-- [Link to another page](./_pages/another-page.html). -->

<!-- # Header 1

This is a normal paragraph following a header. GitHub is a code hosting platform for version control and collaboration. It lets you and others work together on projects from anywhere.

## Header 2

> This is a blockquote following a header.
>
> When something is important enough, you do it even if the odds are not in your favor.

### Header 3

```js
// Javascript code with syntax highlighting.
var fun = function lang(l) {
  dateformat.i18n = require('./lang/' + l)
  return true;
}
```

```ruby
# Ruby code with syntax highlighting
GitHubPages::Dependencies.gems.each do |gem, version|
  s.add_dependency(gem, "= #{version}")
end
```

#### Header 4

*   This is an unordered list following a header.
*   This is an unordered list following a header.
*   This is an unordered list following a header.

##### Header 5

1.  This is an ordered list following a header.
2.  This is an ordered list following a header.
3.  This is an ordered list following a header.

###### Header 6

| head1        | head two          | three |
|:-------------|:------------------|:------|
| ok           | good swedish fish | nice  |
| out of stock | good and plenty   | nice  |
| ok           | good `oreos`      | hmm   |
| ok           | good `zoute` drop | yumm  |

### There's a horizontal rule below this.

* * *

### Here is an unordered list:

*   Item foo
*   Item bar
*   Item baz
*   Item zip

### And an ordered list:

1.  Item one
1.  Item two
1.  Item three
1.  Item four

### And a nested list:

- level 1 item
  - level 2 item
  - level 2 item
    - level 3 item
    - level 3 item
- level 1 item
  - level 2 item
  - level 2 item
  - level 2 item
- level 1 item
  - level 2 item
  - level 2 item
- level 1 item

### Small image

![Octocat](https://github.githubassets.com/images/icons/emoji/octocat.png)

### Large image

![Branching](https://guides.github.com/activities/hello-world/branching.png)


### Definition lists can be used with HTML syntax.

<dl>
<dt>Name</dt>
<dd>Godzilla</dd>
<dt>Born</dt>
<dd>1952</dd>
<dt>Birthplace</dt>
<dd>Japan</dd>
<dt>Color</dt>
<dd>Green</dd>
</dl>

```
Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this.
```

```
The final element.
``` -->


      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>
